# ğŸ•·ï¸ Scraper Portable - Ton Assistant d'Extraction de Contacts

> **En gros :** Un script Python qui visite des sites web et rÃ©cupÃ¨re automatiquement tous les emails, noms et numÃ©ros de tÃ©lÃ©phone. Zero config compliquÃ©e, il s'installe tout seul ! ğŸš€

---

## ğŸ¯ C'est quoi exactement ?

Imagine : tu veux rÃ©cupÃ©rer tous les contacts d'un site (Ã©quipe, direction, staff...). Au lieu de copier-coller pendant des heures comme un robot, tu lances ce petit script, tu lui files l'URL du site, et **boom** ğŸ’¥ il te sort un joli fichier JSON avec tous les contacts bien organisÃ©s.

**Le meilleur dans tout Ã§a ?** Pas besoin d'installer 50 trucs avant, le script gÃ¨re tout automatiquement. Tu lances, Ã§a roule !

---

## ğŸ“¦ Ce qu'il y a dans le pack

```
ğŸ“ ton-dossier/
â”œâ”€â”€ ğŸ portable_scraper.py      # Le boss (c'est lui qui fait tout â­)
â”œâ”€â”€ ğŸ—„ï¸ recreate_table.sql       # Pour crÃ©er ta base de donnÃ©es
â”œâ”€â”€ âš™ï¸ .env.example              # Config exemple (super pratique)
â”œâ”€â”€ ğŸ”§ setup_venv.sh            # Script magique pour Mac
â””â”€â”€ ğŸ“– README.md                 # Le guide que tu lis lÃ  ğŸ‘‹
```

---

## ğŸš€ Installation Ultra Rapide (5 min chrono)

### Ã‰tape 1ï¸âƒ£ : Check si t'as Python

Ouvre ton terminal et tape :
```bash
python --version
# ou si Ã§a marche pas :
python3 --version
```

Il te faut **Python 3.7 minimum**. Si c'est OK, passe direct Ã  l'Ã©tape 2. Sinon, va sur [python.org](https://python.org) pour l'installer (c'est gratuit et rapide).

---

### Ã‰tape 2ï¸âƒ£ : PrÃ©pare ton environnement

#### Sur macOS ğŸ (avec Homebrew)
```bash
# Un seul coup et c'est rÃ©glÃ© !
source setup_venv.sh
```
> ğŸ’¡ **Pourquoi ?** Depuis Python 3.13+, Apple a mis des restrictions. Cet environnement virtuel contourne Ã§a proprement.

#### Sur Linux/Windows ğŸ§ğŸªŸ
```bash
# Essaie direct d'abord
python3 portable_scraper.py

# Si Ã§a bloque, crÃ©e un environnement virtuel
python3 -m venv venv
source venv/bin/activate      # Linux/Mac
# OU
venv\Scripts\activate         # Windows
```

> ğŸ’¡ **C'est quoi un venv ?** C'est comme une bulle isolÃ©e pour tes scripts Python. Ã‡a Ã©vite les conflits avec d'autres projets.

---

### Ã‰tape 3ï¸âƒ£ : Configure Supabase (ta base de donnÃ©es gratuite)

#### 3.1 - CrÃ©e ton compte (2 min)

1. Va sur [supabase.com](https://supabase.com)
2. Clique **"Start your project"** (100% gratuit)
3. Connecte-toi avec GitHub ou email
4. CrÃ©e un nouveau projet :
   - **Nom** : `scraper-contacts` (ou ce que tu veux)
   - **Password** : choisis un mot de passe solide
   - **RÃ©gion** : prends le plus proche gÃ©ographiquement
5. Attends 30 sec que Ã§a se crÃ©e â˜•

#### 3.2 - CrÃ©e ta table (30 sec)

1. Dans ton projet Supabase â†’ **"SQL Editor"** (menu gauche)
2. Ouvre le fichier `recreate_table.sql` sur ton PC
3. Copie tout le contenu (Ctrl+A, Ctrl+C)
4. Colle dans l'Ã©diteur Supabase (Ctrl+V)
5. Clique **"RUN"** en bas Ã  droite
6. Message de succÃ¨s = GG ! âœ…

#### 3.3 - RÃ©cupÃ¨re tes clÃ©s (1 min)

1. Menu **Settings** â†’ **API** (l'icÃ´ne engrenage)
2. Note bien ces 2 trucs :
   - **URL** : ressemble Ã  `https://xxxxx.supabase.co`
   - **anon public key** : un long texte qui commence par `eyJ...`

> ğŸ’¡ **Astuce** : Garde Ã§a dans un fichier texte, tu vas en avoir besoin juste aprÃ¨s !

---

### Ã‰tape 4ï¸âƒ£ : Config automatique (optionnel mais top)

Pour pas retaper tes infos Ã  chaque fois :

```bash
# Copie le template
cp .env.example .env

# Ã‰dite avec ton Ã©diteur prÃ©fÃ©rÃ©
nano .env
# ou code .env
# ou vim .env
```

Remplis comme Ã§a :
```env
SUPABASE_URL=https://ton-projet.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUz...ta-grosse-clÃ©-ici
DEFAULT_MAX_PAGES=50
```

Sauvegarde et c'est dans la poche ! Le script chargera tout automatiquement.

---

## ğŸ® Mode d'emploi (super simple)

### Lancer le script

**Sur Mac** :
```bash
source setup_venv.sh          # Active l'environnement
python portable_scraper.py    # C'est parti !
```

**Sur Linux/Windows** :
```bash
python3 portable_scraper.py   # Go !
```

---

### Le script va te poser des questions

**1. URL du site ?**
```
ğŸ”— URL du site Ã  scraper: https://example.com
```
Entre l'URL du site que tu veux scraper.

**2. Combien de pages max ?**
```
ğŸ“„ Nombre max de pages [50]:
```
Laisse vide pour 50 pages, ou tape un chiffre (ex: 10 pour tester).

**3. Config Supabase ?**
```
ğŸ—„ï¸ Utiliser la config .env ? [O/n]:
```
Si t'as fait l'Ã©tape 4, tape juste "O" (ou EntrÃ©e). Sinon, entre tes clÃ©s manuellement.

**4. OÃ¹ sauvegarder ?**
```
ğŸ“ Dossier de sauvegarde:
1) Ici (rÃ©pertoire actuel)
2) Bureau
3) TÃ©lÃ©chargements
4) Autre...
```
Choisis oÃ¹ tu veux le fichier JSON final.

---

### Exemple concret

```
ğŸš€ Scraper Portable Auto-Installable
========================================
âœ… Python 3.11 dÃ©tectÃ©
ğŸ”§ VÃ©rification des dÃ©pendances...
  âœ… requests
  âœ… beautifulsoup4
  âœ… spacy
âœ… Toutes les dÃ©pendances OK !

ğŸ•·ï¸ DÃ©but du crawling de https://example.com
ğŸ“„ Page 1/50: https://example.com
   ğŸ‘¥ 2 personne(s) trouvÃ©e(s)
      â€¢ Jean Dupont - jean.dupont@example.com - 06 12 34 56 78 (1.0)
      â€¢ Marie Martin - marie@example.com - 01 23 45 67 89 (0.9)

ğŸ“„ Page 2/50: https://example.com/team
   ğŸ‘¥ 3 personne(s) trouvÃ©e(s)
   ...

âœ… Crawling terminÃ© - 15 profils trouvÃ©s
ğŸ’¾ 15 personnes sauvegardÃ©es en base Supabase
ğŸ“ Fichier : saves/2025/09-Septembre/30/14h30_example_com_scraping.json

Enjoy! ğŸ‰
```

---

## ğŸ“Š OÃ¹ sont mes rÃ©sultats ?

### Dans Supabase ğŸ—„ï¸

Va sur ton dashboard Supabase â†’ **Table Editor** â†’ table `personnes`

Tu verras tout bien rangÃ© :
- **nom** : ex: "Jean Dupont", "Marie Martin"
- **email** : l'adresse email
- **telephone** : le tel formatÃ© nickel (+33 6...)
- **poste** : le job si trouvÃ© ("Directeur", "CEO"...)
- **source_url** : l'URL d'oÃ¹ Ã§a vient
- **confidence** : score de fiabilitÃ© (0.0 = pas sÃ»r, 1.0 = trÃ¨s sÃ»r)
- **created_at** : timestamp automatique

### Dans un fichier JSON ğŸ“

Structure hyper organisÃ©e par date :

```
saves/
â””â”€â”€ 2025/
    â””â”€â”€ 09-Septembre/
        â””â”€â”€ 30/
            â”œâ”€â”€ 14h30_example_com_scraping.json
            â”œâ”€â”€ 15h45_autre_site_scraping.json
            â””â”€â”€ ...
```

Le JSON ressemble Ã  Ã§a :
```json
[
  {
    "nom": "Jean Dupont",
    "email": "jean.dupont@example.com",
    "telephone": "+33 6 12 34 56 78",
    "poste": "CEO",
    "source_url": "https://example.com/team",
    "confidence": 0.95,
    "created_at": "2025-09-30T14:30:00"
  }
]
```

---

## ğŸ¨ Les trucs stylÃ©s du script

### ğŸ§  IA intÃ©grÃ©e
- Utilise **spaCy** pour reconnaÃ®tre les vrais noms
- Filtre les faux positifs ("Contact", "Team", "About Us"...)
- Score de confiance pour chaque extraction

### ğŸŒ FranÃ§ais + Anglais
- DÃ©tecte automatiquement la langue du site
- GÃ¨re les formats franÃ§ais ET anglais
- TÃ©lÃ©phones franÃ§ais, US, UK, internationaux...

### ğŸ¯ Extraction intelligente
- Trouve les zones "Ã©quipe", "team", "staff" automatiquement
- Regroupe les infos Ã©parpillÃ©es (email en haut, nom en bas = OK !)
- Ã‰vite les doublons tout seul
- Priorise les noms proches des emails

### ğŸ“ Tous les formats de tel
- France : `06 12 34 56 78`, `+33 6 12 34 56 78`, `01.23.45.67.89`
- USA : `+1 234 567 8900`
- UK : `+44 20 1234 5678`
- Contexte : `Tel: 01 23 45 67 89` â†’ dÃ©tectÃ© !

### ğŸ¤ Respectueux
- Pause de 1 sec entre chaque page (pas de spam)
- User-Agent standard (pas repÃ©rÃ© comme bot)
- Reste sur le domaine demandÃ©
- Timeout de 10 sec par page

---

## ğŸ› ï¸ ProblÃ¨mes courants

### "Python 3.7+ requis"
```bash
# Check ta version
python --version

# Trop vieux ? Installe une version rÃ©cente sur python.org
```

### "Ã‰chec installation dÃ©pendances"
```bash
# Sur Mac
source setup_venv.sh
python portable_scraper.py

# Sur autres systÃ¨mes
python -m ensurepip --upgrade
pip install --upgrade pip
```

### "Connexion Supabase failed"
- âœ… URL commence par `https://` ?
- âœ… ClÃ© commence par `eyJ` ?
- âœ… Internet fonctionne ?
- âœ… Projet Supabase crÃ©Ã© ?

### "Table 'personnes' existe pas"
Refais l'Ã©tape 3.2 (copie le SQL dans Supabase)

### "Aucun contact trouvÃ©"
- âœ… Le site a des contacts visibles (pas que des images) ?
- âœ… Langue franÃ§aise ou anglaise ?
- âœ… Pas de login requis ?
- âœ… Pas de Cloudflare/captcha ?

---

## ğŸ’¡ Tips de pro

### Sites qui marchent bien ğŸ‘
- Pages "Notre Ã©quipe" / "Our team"
- Pages contact avec infos
- Annuaires pros
- Sites d'entreprise classiques
- Portfolios personnels

### Sites compliquÃ©s ğŸ‘
- Sites avec captcha (Cloudflare, reCAPTCHA)
- Sites avec login obligatoire
- Sites 100% JavaScript (React/Vue sans SSR)
- RÃ©seaux sociaux (LinkedIn, Facebook...)

### Astuce ğŸ“
**Teste toujours avec 5-10 pages d'abord !**
```
ğŸ“„ Nombre max de pages [50]: 5   # â† Tape 5 pour tester
```
Une fois que tu vois que Ã§a marche, relance avec 50 ou plus.

---

## ğŸ” Ã‰thique & LÃ©galitÃ©

### Ce que fait le script âœ…
- Pause respectueuse entre pages
- User-Agent standard
- Reste sur le domaine
- Utilise que des clÃ©s publiques

### Tes responsabilitÃ©s ğŸ™
- **Respecte la vie privÃ©e** : utilise les donnÃ©es Ã©thiquement
- **Check le robots.txt** du site
- **Pas de spam** : 1 scraping suffit gÃ©nÃ©ralement
- **RGPD** : respecte les lois sur les donnÃ©es
- **Demande permission** si possible au proprio du site

> âš ï¸ **Important** : Tu es responsable de comment tu utilises ce script. Utilise-le lÃ©galement et Ã©thiquement !

---

## ğŸ‰ C'est tout !

Si t'as suivi ce guide, t'as maintenant :
- âœ… Un scraper qui tourne
- âœ… Une base Supabase configurÃ©e
- âœ… Des contacts extraits proprement

### Besoin d'aide ?
1. Relis calmement ce README
2. Check les logs d'erreur
3. Google ton message d'erreur
4. Teste avec un site simple d'abord

---

**Fait avec â¤ï¸ - Happy Scraping ! ğŸ•·ï¸**

*PS : Utilise ce pouvoir avec sagesse ğŸ˜*
